{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to base (Python 3.12.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20475a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "import datetime\n",
    "import logging\n",
    "import yaml\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics.classification import BinaryPrecisionRecallCurve\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.tft import TFTModel\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.train.tft import train_tft\n",
    "from src.utils.utils import TrainConfig, FocalLoss, collate_with_macro\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> TFTModel:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(\"../\" + cfg.firm_data),\n",
    "        macro_paths = [str(id) for id in cfg.macro_data],\n",
    "        bankruptcy_col = str(cfg.bankruptcy_col),\n",
    "        company_col=str(cfg.company_col),\n",
    "        revenue_cap=int(cfg.revenue_cap),\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        device=str(cfg.device),\n",
    "        hidden_size=int(cfg.hidden_size),\n",
    "        output_size=1,\n",
    "        epochs=int(cfg.epochs),\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=float(cfg.train_fract),\n",
    "        dropout=int(cfg.dropout),\n",
    "        alpha=float(cfg.alpha),\n",
    "        gamma=float(cfg.alpha),\n",
    "        scheduler_factor=float(cfg.scheduler_factor),\n",
    "        scheduler_patience=int(cfg.scheduler_patience),\n",
    "        stopping_patience=int(cfg.stopping_patience),\n",
    "        seed=int(cfg.seed)\n",
    "    )\n",
    "\n",
    "def train(\n",
    "    company_path: str,\n",
    "    macro_paths: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    num_layers: int = 2,\n",
    "    hidden_size: int = 64,\n",
    "    output_size: int = 1,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-3,\n",
    "    train_fract: float = 0.8,\n",
    "    dropout: float = 0.2,\n",
    "    alpha: float = 0.9,\n",
    "    gamma: float = 2.0,\n",
    "    scheduler_factor: float = 0.85,\n",
    "    scheduler_patience: int = 50,\n",
    "    stopping_patience: int = 10,\n",
    "    stopping_window: int = 5,\n",
    "    min_lr: float = 0.0,\n",
    "    device: str=\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "):  \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_path=company_path,\n",
    "        macro_paths=macro_paths,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    \n",
    "    ingestion.run()\n",
    "    X, M_past, M_future, y = ingestion.get_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_past_tensor = M_past,\n",
    "        macro_future_tensor = M_future,\n",
    "        labels = y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    metrics.to(device)\n",
    "    train_ds = train_ds.to_device(device)\n",
    "    val_ds = val_ds.to_device(device)\n",
    "    \n",
    "    firm_input_size, macro_past_input_size, macro_future_input_size = dataset.input_dims()\n",
    "    firm_input_size = firm_input_size[-1]\n",
    "    macro_past_input_size = macro_past_input_size[-1]\n",
    "    macro_future_input_size = macro_future_input_size[-1]\n",
    "    \n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "    mlflow.set_experiment('bankruptcy-predictions')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model_type\", \"tft\")\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        model = TFTModel(\n",
    "            static_input_dim=0,\n",
    "            company_input_dim=firm_input_size,\n",
    "            macro_input_dim=macro_past_input_size,\n",
    "            decoder_input_dim=macro_future_input_size,\n",
    "            hidden_dim=hidden_size,\n",
    "            attention_heads=4,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        pos_weight = dataset.pos_weight()\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        decay, no_decay = [], []\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            if any(nd in name for nd in [\"bias\", \"LayerNorm.weight\"]):\n",
    "                no_decay.append(param)\n",
    "            else:\n",
    "                decay.append(param)\n",
    "        \n",
    "        optimizer = AdamW(\n",
    "            [{\"params\": decay, \"weight_decay\": 1e-4},\n",
    "            {\"params\": no_decay, \"weight_decay\": 0.0}],\n",
    "            lr=lr\n",
    "        )\n",
    "        scheduler=ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        \n",
    "        train_tft(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            stopping_patience=stopping_patience,\n",
    "            stopping_window=stopping_window,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        model_name = f\"TFTModel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        mlflow.pytorch.log_model(model, model_name)\n",
    "        torch.save(obj = model.state_dict(), f = f\"../models/{model_name}.pth\")\n",
    "        print(f\"Model saved: {model_name}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbeee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = load_yaml_file(\"../config/tft_config.yml\")\n",
    "cfg = TrainConfig(**config_dict)\n",
    "\n",
    "company_data_path = Path(\"../\" + cfg.firm_data)\n",
    "macro_data_path = [str(id) for id in cfg.macro_data]\n",
    "bankruptcy_col = str(cfg.bankruptcy_col)\n",
    "company_col=str(cfg.company_col)\n",
    "revenue_cap=int(cfg.revenue_cap)\n",
    "metrics=cfg.get_metrics().to(cfg.device)\n",
    "device=str(cfg.device)\n",
    "num_layers=int(cfg.num_classes)\n",
    "hidden_size=int(cfg.hidden_size)\n",
    "output_size=1\n",
    "epochs=int(cfg.epochs)\n",
    "lr=float(cfg.lr)\n",
    "train_fract=float(cfg.train_fract)\n",
    "dropout=int(cfg.dropout)\n",
    "scheduler_factor=float(cfg.scheduler_factor)\n",
    "scheduler_patience=int(cfg.scheduler_patience)\n",
    "seed=int(cfg.seed)\n",
    "\n",
    "ingestion = IngestionPipeline(\n",
    "    company_path=company_data_path,\n",
    "    macro_paths=macro_data_path,\n",
    "    company_col=company_col,\n",
    "    bankruptcy_col=bankruptcy_col,\n",
    "    revenue_cap=revenue_cap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data2.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Applying feature engineering...\n",
      "INFO:src.data.feature_engineer:Fitting feature engineer...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/010774417\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001763782\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001587668\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Financial data tensor shape: (6318, 3, 13)\n",
      "INFO:src.data.tensor_factory:Converting macroeconomic series to tensors...\n",
      "INFO:src.data.tensor_factory:Downsampling macro data to annual resolution...\n",
      "INFO:src.data.tensor_factory:Macro data tensor shape: torch.Size([3, 1]) (past), torch.Size([3, 1]) (future)\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past: torch.Size([3, 1]), Future: torch.Size([3, 1])\n",
      "Data sent to device: mps\n",
      "Data sent to device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:19<?, ?it/s]\n",
      "ERROR:root:Training failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_32522/1801138688.py\", line 3, in <module>\n",
      "    model = train_model_from_config(cfg)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_32522/3930155588.py\", line 47, in train_model_from_config\n",
      "    return train(\n",
      "           ^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_32522/3930155588.py\", line 177, in train\n",
      "    train_tft(\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/train/tft.py\", line 124, in train_tft\n",
      "    train_loss, train_metrics = train_one_epoch(\n",
      "                                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/train/tft.py\", line 37, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/adamw.py\", line 243, in step\n",
      "    adamw(\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 154, in maybe_fallback\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/adamw.py\", line 875, in adamw\n",
      "    func(\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/optim/adamw.py\", line 477, in _single_tensor_adamw\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bouncy-skink-243 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/43022b6ced0548cc8353f62f3e448987\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data2.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Applying feature engineering...\n",
      "INFO:src.data.feature_engineer:Fitting feature engineer...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/010774417\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001763782\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001587668\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Financial data tensor shape: (6318, 3, 13)\n",
      "INFO:src.data.tensor_factory:Converting macroeconomic series to tensors...\n",
      "INFO:src.data.tensor_factory:Downsampling macro data to annual resolution...\n",
      "INFO:src.data.tensor_factory:Macro data tensor shape: torch.Size([3, 1]) (past), torch.Size([3, 1]) (future)\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past: torch.Size([3, 1]), Future: torch.Size([3, 1])\n",
      "Data sent to device: mps\n",
      "Data sent to device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    try:\n",
    "        model = train_model_from_config(cfg)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "    except:\n",
    "        logging.error(\"Training failed.\", exc_info=True)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2698be",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "ingestion = IngestionPipeline(\n",
    "    company_path=\"../\" + cfg.firm_data,\n",
    "    macro_paths=cfg.macro_data,\n",
    "    company_col=cfg.company_col,\n",
    "    bankruptcy_col=cfg.bankruptcy_col,\n",
    "    revenue_cap=cfg.revenue_cap\n",
    ")\n",
    "\n",
    "ingestion.run()\n",
    "X, M_past, M_future, y = ingestion.get_tensors()\n",
    "\n",
    "dataset = DualInputSequenceDataset(\n",
    "    firm_tensor = X,\n",
    "    macro_past_tensor = M_past,\n",
    "    macro_future_tensor = M_future,\n",
    "    labels = y\n",
    ")\n",
    "\n",
    "train_ds, val_ds, seed = dataset.stratified_split(train_fract)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc198d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

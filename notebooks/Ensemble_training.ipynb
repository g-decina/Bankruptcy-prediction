{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2947d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "import datetime\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric, MetricCollection\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy, BinaryAUROC, BinaryF1Score, BinaryMatthewsCorrCoef,\n",
    "    MulticlassAccuracy, MulticlassAUROC, MulticlassF1Score)\n",
    "from pathlib import Path\n",
    "\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.gru import GRUModel\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.train import train_model\n",
    "from src.utils.utils import CustomReduceLROnPlateau, collate_with_macro\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    firm_data: str\n",
    "    macro_data: list[str]\n",
    "    bankruptcy_col: str\n",
    "    company_col: str\n",
    "    revenue_cap: int = 3_000\n",
    "    num_classes: int = 2\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 40\n",
    "    lr: float = 1e-3\n",
    "    hidden_size: int = 64\n",
    "    num_layers: int = 2\n",
    "    dropout: float = .2\n",
    "    threshold: float = 0.5\n",
    "    alpha: float = 0.9\n",
    "    gamma: float = 2.0\n",
    "    scheduler_factor: float = 0.85\n",
    "    scheduler_patience: int = 50\n",
    "    stopping_patience: int = 10\n",
    "    min_lr:float = 0.0\n",
    "    decay_ih: float = 1e-5\n",
    "    decay_hh: float = 1e-5\n",
    "    decay_other: float = 1e-5\n",
    "    train_fract: float = .8\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "    metrics: list[str] = field(default_factory=lambda: [\"f1\", \"accuracy\"])\n",
    "    \n",
    "    def get_metrics(self) -> MetricCollection:\n",
    "        \"\"\"Constructs a MetricCollection from the specified config\"\"\"\n",
    "        if self.num_classes == 2:\n",
    "            available = {\n",
    "                \"f1\": BinaryF1Score(self.threshold),\n",
    "                \"accuracy\": BinaryAccuracy(self.threshold),\n",
    "                \"auroc\": BinaryAUROC(),\n",
    "                \"matthews\": BinaryMatthewsCorrCoef(self.threshold)\n",
    "            }\n",
    "        else:\n",
    "            available = {\n",
    "                \"f1\": MulticlassF1Score(num_classes=self.num_classes),\n",
    "                \"accuracy\": MulticlassAccuracy(num_classes=self.num_classes),\n",
    "                \"auroc\": MulticlassAUROC(num_classes=self.num_classes)\n",
    "            }\n",
    "        selected = {k: available[k] for k in self.metrics if k in available}\n",
    "        return MetricCollection(selected)\n",
    "    \n",
    "def _make_class_weights(labels: torch.Tensor, num_classes:int) -> torch.Tensor:\n",
    "    \"\"\"Helper function to compute class weights.\"\"\"\n",
    "    counts = torch.bincount(labels.long(), minlength=num_classes)\n",
    "    weights = counts.sum() / (num_classes * counts.float())\n",
    "    return weights\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> GRUModel:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(\"../\" + cfg.firm_data),\n",
    "        macro_paths = [Path(\"../\" + path) for path in cfg.macro_data],\n",
    "        bankruptcy_col = str(cfg.bankruptcy_col),\n",
    "        company_col=str(cfg.company_col),\n",
    "        revenue_cap=int(cfg.revenue_cap),\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        device=str(cfg.device),\n",
    "        num_layers=int(cfg.num_classes),\n",
    "        hidden_size=int(cfg.hidden_size),\n",
    "        output_size=1,\n",
    "        epochs=int(cfg.epochs),\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=float(cfg.train_fract),\n",
    "        dropout=int(cfg.dropout),\n",
    "        alpha=float(cfg.alpha),\n",
    "        gamma=float(cfg.alpha),\n",
    "        scheduler_factor=float(cfg.scheduler_factor),\n",
    "        scheduler_patience=int(cfg.scheduler_patience),\n",
    "        stopping_patience=int(cfg.stopping_patience),\n",
    "        decay_ih=float(cfg.decay_ih),\n",
    "        decay_hh=float(cfg.decay_hh),\n",
    "        decay_other=float(cfg.decay_other),\n",
    "        seed=int(cfg.seed)\n",
    "    )\n",
    "\n",
    "def train(\n",
    "    company_data_path: str,\n",
    "    macro_data_path: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    num_layers: int = 2,\n",
    "    hidden_size: int = 64,\n",
    "    output_size: int = 1,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-3,\n",
    "    train_fract: float = 0.8,\n",
    "    dropout: float = 0.2,\n",
    "    scheduler_factor: float = 0.85,\n",
    "    scheduler_patience: int = 50,\n",
    "    min_lr: float = 0.0,\n",
    "    decay_ih:float = 1e-5,\n",
    "    decay_hh:float = 1e-5,\n",
    "    decay_other:float = 1e-5,\n",
    "    device: str=\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "):  \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_data_path=company_data_path,\n",
    "        macro_data_path=macro_data_path,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        sheet_name=\"Results\",\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    ingestion.load()\n",
    "    series = ingestion.process_data()\n",
    "    financials, macro, labels = series.export_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = financials,\n",
    "        macro_tensor = macro,\n",
    "        labels = labels\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_with_macro)\n",
    "\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    metrics_dict = dict()\n",
    "    for metric in metrics:\n",
    "        metrics_dict[metric._get_name()] = metric.to(device)\n",
    "    metrics = metrics_dict \n",
    "    \n",
    "    train_ds = train_ds.to_device(device)\n",
    "    val_ds = val_ds.to_device(device)\n",
    "    \n",
    "    firm_input_size, macro_input_size = dataset.input_dims()\n",
    "    \n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "    mlflow.set_experiment('bankruptcy-predictions')\n",
    "    \n",
    "    mlflow.log_param(\"seed\", seed)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        model = GRUModel(\n",
    "            firm_input_size=firm_input_size,\n",
    "            macro_input_size=macro_input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=output_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        pos_weight = dataset.pos_weight()\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "        mlflow.log_param(\"output_size\", output_size)\n",
    "        mlflow.log_param(\"num_layers\", num_layers)\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "        ih_params = []\n",
    "        hh_params = []\n",
    "        other_params = []\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                ih_params.append(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                hh_params.append(param)\n",
    "            else:\n",
    "                other_params.append(param)\n",
    "        \n",
    "        optimizer = Adam([\n",
    "                {'params': ih_params, 'weight_decay': decay_ih},\n",
    "                {'params': hh_params, 'weight_decay': decay_hh},\n",
    "                {'params': other_params, 'weight_decay': decay_other},\n",
    "            ], lr=lr\n",
    "        )\n",
    "        scheduler=CustomReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        \n",
    "        train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        mlflow.pytorch.log_model(model, f\"model_{datetime.datetime.now()}\")\n",
    "        torch.save(obj = model.state_dict(), f = f\"model_{datetime.datetime.now()}.pth\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4150d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = load_yaml_file(\"../config/model_config.yml\")\n",
    "cfg = TrainConfig(**config_dict)\n",
    "\n",
    "company_data_path = Path(\"../\" + cfg.firm_data)\n",
    "macro_data_path = [Path(\"../\" + path) for path in cfg.macro_data]\n",
    "bankruptcy_col = str(cfg.bankruptcy_col)\n",
    "company_col=str(cfg.company_col)\n",
    "revenue_cap=int(cfg.revenue_cap)\n",
    "metrics=cfg.get_metrics().to(cfg.device)\n",
    "device=str(cfg.device)\n",
    "num_layers=int(cfg.num_classes)\n",
    "hidden_size=int(cfg.hidden_size)\n",
    "output_size=1\n",
    "epochs=int(cfg.epochs)\n",
    "lr=float(cfg.lr)\n",
    "train_fract=float(cfg.train_fract)\n",
    "dropout=int(cfg.dropout)\n",
    "scheduler_factor=float(cfg.scheduler_factor)\n",
    "scheduler_patience=int(cfg.scheduler_patience)\n",
    "decay_ih=float(cfg.decay_ih)\n",
    "decay_hh=float(cfg.decay_hh)\n",
    "decay_other=float(cfg.decay_other)\n",
    "seed=int(cfg.seed)\n",
    "\n",
    "ingestion = IngestionPipeline(\n",
    "    company_path=company_data_path,\n",
    "    macro_paths=macro_data_path,\n",
    "    company_col=company_col,\n",
    "    bankruptcy_col=bankruptcy_col,\n",
    "    revenue_cap=revenue_cap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cefa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/dtwb4c1s.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/sgtzxgaq.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=13408', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/dtwb4c1s.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/sgtzxgaq.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/prophet_model2x08faqm/prophet_model-20250724070022.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "07:00:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "07:00:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/jfv8tj9e.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/5xa42dw7.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41411', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/jfv8tj9e.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/5xa42dw7.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/prophet_model0atr6o5t/prophet_model-20250724070023.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "07:00:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "07:00:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/3_pz8r19.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/118_ieb5.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=10149', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/3_pz8r19.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/118_ieb5.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmp2zxrhr_4/prophet_model8smmo2z6/prophet_model-20250724070023.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "07:00:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "07:00:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n"
     ]
    }
   ],
   "source": [
    "ingestion.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f36ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n"
     ]
    }
   ],
   "source": [
    "X, M, y = ingestion.get_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4da2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_tensor = M,\n",
    "        labels = y\n",
    "    )\n",
    "\n",
    "train_ds, val_ds, seed = dataset.stratified_split(train_fract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a4c3f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_with_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11feb902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent to device: mps\n",
      "Data sent to device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/387584985157093548', creation_time=1743696743728, experiment_id='387584985157093548', last_update_time=1751272195574, lifecycle_stage='active', name='bankruptcy-predictions', tags={'mlflow.sharedViewState.6eefdeeb55bdab552f034c238b95f9924e315a9316ba27c5c5d5a648aacfdaa5': 'deflate;eJztmd9P20AMx/8VlGc0UbpSWmkPpYMNrWxTy9AkNsHl4iaml7vsfoQExP8+p2mbDFptD5MWaXmM785nfz9u6taPngGmeXSGwoL2hp5loXkF0kDsC9h7s/fN63zzvH1P6QD0Sf4BctoUg9XIzavblImbE5RM5xfM2gjuzVhpPVYwv63OjAz3hnMmDOx7xjJtLzEG8jKaTGiTwDnwnAvYhDDiFlOgpYBZZsCa9cr1930vVgGIK9AGlaxOCLE3ddLQGQMCuIVgrISLyTK89igyjb6zQAHPlNMciuDq1ovCqXlufVteX5j/MOEt2846M6407FgdpaBZCJ81cCwyuvUoRU2ZnGYJkwEE3vDxqbR8RimL5+vVjvcYBCCr5yty4KNAS5El1bFyW5Eg6XR2Pp1d3nQObqZfPs4oIq7ihGkg6cYRcSnUevScQ7rG6/R7B4NerzfoHnY74UBHJhGWztg8KVxNzj+eeuUVY+WkvVTj0pk37Bysc50RCsrq/IW/KBOuH0esgEzAbJHYqkLQvANJqixtVjtYOytLjzm+LBoJs1gpG0kwFDbdmI0yNDPOBFyWERZ7mC5KYptRMxlCKdPyZOndWEhqRfS1WLmo3U5rebW7jGttI2SagqF8TUkFQ0nkPzkrkOp1k6Az8E4on4mvbO2pTHOzMNlkhzIsV5/2t4M5FJEd3KsGgJl3Wi6Vjgt9FOHi+OjfcxHKmJZM7VWmBxH3j/IGkNEtl5qO9527Y9QN+MRYzVCuv6C/TD+NW0yVrCJ7zZCzqGGYnvVRLbFK4YN+2tNc95tFbNUXt6AqYUnvuUyO580C9fx3TkusUnjA9A/t87RZxNq34BZUyYCLPrKwWaimQJKLllOlK0sPfyS8120Kp7ZJr6spbWyBOf3v6dT+Q2tb9F9FtXeJGdgH2ShIbYO+k1eWWqu7C9YkXm17/kLWLoZBkPoNaM93DyFaXpW+Jr3rLQL30CRe7ftv2z9/BsPD11kDZhgVqLYxf/EtdewQ0M+aQem/nWp8r09tV+LuntvWRJZsOXRfjrr3VqPoQns0iWCbu9FMYTm2r+H4LZ6dH2ydLY4WqKrbZzkpG//t60mTFOH+gnSM8aG2lUpzgsauR+UbByNOzU1Ayr28rRBfK5dAcMWEA3O+GY2XEUYYwGmc2PxXc1icOaE8pBNi9fhsiM+cVVOYU21Ep5L5oirucEN76XSs5ByJ9+OWitxS8LuL9OnpJ1rGk7M='}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.to(device)\n",
    "train_ds = train_ds.to_device(device)\n",
    "val_ds = val_ds.to_device(device)\n",
    "\n",
    "firm_input_size, macro_input_size = dataset.input_dims()\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "mlflow.set_experiment('bankruptcy-predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4a53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run gregarious-skink-32 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/8a7bff62dadf4731a4905ed9034aeb24\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got torch.Size\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run():\n\u001b[32m      3\u001b[39m     mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m, seed)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     model = \u001b[43mGRUModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirm_input_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirm_input_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_input_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmacro_input_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     model = model.to(device)\n\u001b[32m     15\u001b[39m     pos_weight = dataset.pos_weight()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/models/gru.py:21\u001b[39m, in \u001b[36mGRUModel.__init__\u001b[39m\u001b[34m(self, firm_input_size, macro_input_size, hidden_size, output_size, num_layers, dropout)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ---- For company-level data ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28mself\u001b[39m.firm_gru = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirm_input_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# ---- For macro-level data ----\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.macro_gru = nn.GRU(\n\u001b[32m     31\u001b[39m     input_size = macro_input_size, \n\u001b[32m     32\u001b[39m     hidden_size = hidden_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     dropout = dropout \u001b[38;5;28;01mif\u001b[39;00m num_layers > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m     36\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1316\u001b[39m, in \u001b[36mGRU.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mproj_size\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1314\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproj_size argument is only supported for LSTM, not RNN or GRU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1315\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1316\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGRU\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:166\u001b[39m, in \u001b[36mRNNBase.__init__\u001b[39m\u001b[34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size, device, dtype)\u001b[39m\n\u001b[32m    160\u001b[39m real_hidden_size = proj_size \u001b[38;5;28;01mif\u001b[39;00m proj_size > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m hidden_size\n\u001b[32m    161\u001b[39m layer_input_size = (\n\u001b[32m    162\u001b[39m     input_size \u001b[38;5;28;01mif\u001b[39;00m layer == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m real_hidden_size * num_directions\n\u001b[32m    163\u001b[39m )\n\u001b[32m    165\u001b[39m w_ih = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_input_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m )\n\u001b[32m    168\u001b[39m w_hh = Parameter(\n\u001b[32m    169\u001b[39m     torch.empty((gate_size, real_hidden_size), **factory_kwargs)\n\u001b[32m    170\u001b[39m )\n\u001b[32m    171\u001b[39m b_ih = Parameter(torch.empty(gate_size, **factory_kwargs))\n",
      "\u001b[31mTypeError\u001b[39m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got torch.Size\""
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.log_param(\"seed\", seed)\n",
    "    model = GRUModel(\n",
    "        firm_input_size=firm_input_size,\n",
    "        macro_input_size=macro_input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        output_size=output_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    pos_weight = dataset.pos_weight()\n",
    "    loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    \n",
    "    # Logging hyperparameters\n",
    "    mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "    mlflow.log_param(\"output_size\", output_size)\n",
    "    mlflow.log_param(\"num_layers\", num_layers)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "    ih_params = []\n",
    "    hh_params = []\n",
    "    other_params = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight_ih' in name:\n",
    "            ih_params.append(param)\n",
    "        elif 'weight_hh' in name:\n",
    "            hh_params.append(param)\n",
    "        else:\n",
    "            other_params.append(param)\n",
    "    \n",
    "    optimizer = Adam([\n",
    "            {'params': ih_params, 'weight_decay': decay_ih},\n",
    "            {'params': hh_params, 'weight_decay': decay_hh},\n",
    "            {'params': other_params, 'weight_decay': decay_other},\n",
    "        ], lr=lr\n",
    "    )\n",
    "    scheduler=CustomReduceLROnPlateau(\n",
    "        optimizer=optimizer,\n",
    "        mode=\"min\",\n",
    "        factor=scheduler_factor,\n",
    "        patience=scheduler_patience,\n",
    "        min_lr=0.0\n",
    "    )\n",
    "    \n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, f\"model_{datetime.datetime.now()}\")\n",
    "    torch.save(obj = model.state_dict(), f = f\"model_{datetime.datetime.now()}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9525f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6338, 3, 4)\n",
      "torch.Size([3, 422])\n",
      "(6338,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(M.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import mlflow\n",
    "import datetime\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric, MetricCollection\n",
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy, BinaryAUROC, BinaryF1Score, BinaryMatthewsCorrCoef,\n",
    "    MulticlassAccuracy, MulticlassAUROC, MulticlassF1Score)\n",
    "from pathlib import Path\n",
    "\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.gru import GRUModel\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.train import train_model\n",
    "from src.utils.utils import CustomReduceLROnPlateau, collate_with_macro\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    firm_data: str\n",
    "    macro_data: list[str]\n",
    "    bankruptcy_col: str\n",
    "    company_col: str\n",
    "    revenue_cap: int = 3_000\n",
    "    num_classes: int = 2\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 40\n",
    "    lr: float = 1e-3\n",
    "    hidden_size: int = 64\n",
    "    num_layers: int = 2\n",
    "    dropout: float = .2\n",
    "    threshold: float = 0.5\n",
    "    scheduler_factor: float=0.85\n",
    "    scheduler_patience: int = 50\n",
    "    min_lr:float = 0.0\n",
    "    decay_ih: float = 1e-5\n",
    "    decay_hh: float = 1e-5\n",
    "    decay_other: float = 1e-5\n",
    "    train_fract: float = .8\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "    metrics: list[str] = field(default_factory=lambda: [\"f1\", \"accuracy\"])\n",
    "    \n",
    "    def get_metrics(self) -> MetricCollection:\n",
    "        \"\"\"Constructs a MetricCollection from the specified config\"\"\"\n",
    "        if self.num_classes == 2:\n",
    "            available = {\n",
    "                \"f1\": BinaryF1Score(self.threshold),\n",
    "                \"accuracy\": BinaryAccuracy(self.threshold),\n",
    "                \"auroc\": BinaryAUROC(),\n",
    "                \"matthews\": BinaryMatthewsCorrCoef(self.threshold)\n",
    "            }\n",
    "        else:\n",
    "            available = {\n",
    "                \"f1\": MulticlassF1Score(num_classes=self.num_classes),\n",
    "                \"accuracy\": MulticlassAccuracy(num_classes=self.num_classes),\n",
    "                \"auroc\": MulticlassAUROC(num_classes=self.num_classes)\n",
    "            }\n",
    "        selected = {k: available[k] for k in self.metrics if k in available}\n",
    "        return MetricCollection(selected)\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> GRUModel:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(cfg.firm_data),\n",
    "        macro_paths = [Path(path) for path in cfg.macro_data],\n",
    "        bankruptcy_col = str(cfg.bankruptcy_col),\n",
    "        company_col=str(cfg.company_col),\n",
    "        revenue_cap=int(cfg.revenue_cap),\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        device=str(cfg.device),\n",
    "        num_layers=int(cfg.num_classes),\n",
    "        hidden_size=int(cfg.hidden_size),\n",
    "        output_size=1,\n",
    "        epochs=int(cfg.epochs),\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=float(cfg.train_fract),\n",
    "        dropout=int(cfg.dropout),\n",
    "        scheduler_factor=float(cfg.scheduler_factor),\n",
    "        scheduler_patience=int(cfg.scheduler_patience),\n",
    "        decay_ih=float(cfg.decay_ih),\n",
    "        decay_hh=float(cfg.decay_hh),\n",
    "        decay_other=float(cfg.decay_other),\n",
    "        seed=int(cfg.seed)\n",
    "    )\n",
    "\n",
    "def train(\n",
    "    company_path: str,\n",
    "    macro_paths: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    num_layers: int = 2,\n",
    "    hidden_size: int = 64,\n",
    "    output_size: int = 1,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-3,\n",
    "    train_fract: float = 0.8,\n",
    "    dropout: float = 0.2,\n",
    "    scheduler_factor: float = 0.85,\n",
    "    scheduler_patience: int = 50,\n",
    "    min_lr: float = 0.0,\n",
    "    decay_ih:float = 1e-5,\n",
    "    decay_hh:float = 1e-5,\n",
    "    decay_other:float = 1e-5,\n",
    "    device: str=\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "):  \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_path=company_path,\n",
    "        macro_paths=macro_paths,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    \n",
    "    ingestion.run()\n",
    "    X, M, y = ingestion.get_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_tensor = M,\n",
    "        labels = y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_with_macro)\n",
    "\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    metrics.to(device)\n",
    "    train_ds = train_ds.to_device(device)\n",
    "    val_ds = val_ds.to_device(device)\n",
    "    \n",
    "    firm_input_size, macro_input_size = dataset.input_dims()\n",
    "    \n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "    mlflow.set_experiment('bankruptcy-predictions')\n",
    "    \n",
    "    mlflow.log_param(\"seed\", seed)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        model = GRUModel(\n",
    "            firm_input_size=firm_input_size,\n",
    "            macro_input_size=macro_input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=output_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        pos_weight = dataset.pos_weight()\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "        mlflow.log_param(\"output_size\", output_size)\n",
    "        mlflow.log_param(\"num_layers\", num_layers)\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "\n",
    "        ih_params = []\n",
    "        hh_params = []\n",
    "        other_params = []\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'weight_ih' in name:\n",
    "                ih_params.append(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                hh_params.append(param)\n",
    "            else:\n",
    "                other_params.append(param)\n",
    "        \n",
    "        optimizer = Adam([\n",
    "                {'params': ih_params, 'weight_decay': decay_ih},\n",
    "                {'params': hh_params, 'weight_decay': decay_hh},\n",
    "                {'params': other_params, 'weight_decay': decay_other},\n",
    "            ], lr=lr\n",
    "        )\n",
    "        scheduler=CustomReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        \n",
    "        train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        model_name = f\"EnsembleModel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        mlflow.pytorch.log_model(model, model_name)\n",
    "        torch.save(obj = model.state_dict(), f = f\"../models/{model_name}.pth\")\n",
    "        print(f\"Model saved: {model_name}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc0d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainConfig(firm_data='data/demo_data.xlsx', macro_data=['insee/serie_000857176_04042025/valeurs_mensuelles.csv', 'insee/serie_000857180_04042025/valeurs_mensuelles.csv', 'insee/serie_001763782_04042025/valeurs_mensuelles.csv'], bankruptcy_col='Status date', company_col='Company name Latin alphabet', revenue_cap=3000, num_classes=2, batch_size=32, epochs=100, lr='1e-3', hidden_size=64, num_layers=2, dropout=0.4, threshold=0.4, scheduler_factor=0.85, scheduler_patience=50, min_lr=0.0, decay_ih='1e-5', decay_hh='1e-4', decay_other='1e-5', train_fract=0.8, seed=2025, device='mps', metrics=['f1', 'accuracy', 'auroc', 'matthews'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:126: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:126: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:126: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/v3to4gc7.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/dtv1fhag.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=15692', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/v3to4gc7.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/dtv1fhag.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/prophet_modelbgoaxg3a/prophet_model-20250628192627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/aa67vq2w.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/7j7duo0k.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=69653', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/aa67vq2w.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/7j7duo0k.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/prophet_model_lrsx9ak/prophet_model-20250628192627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/9xt8mtzs.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/gukp79dk.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=17199', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/9xt8mtzs.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/gukp79dk.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpb0h5k1st/prophet_modellrjtpimp/prophet_model-20250628192627.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "19:26:27 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6338, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 422])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Run with UUID 06653c474f224c5086793f7ff21e61b6 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mtrain_model_from_config\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model_from_config\u001b[39m(cfg: TrainConfig) -> GRUModel:\n\u001b[32m     83\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Main training function\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfirm_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_paths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmacro_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevenue_cap\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrevenue_cap\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecay_ih\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecay_ih\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecay_hh\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecay_hh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecay_other\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecay_other\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(company_path, macro_paths, bankruptcy_col, company_col, revenue_cap, metrics, seed, num_layers, hidden_size, output_size, epochs, lr, train_fract, dropout, scheduler_factor, scheduler_patience, min_lr, decay_ih, decay_hh, decay_other, device)\u001b[39m\n\u001b[32m    163\u001b[39m mlflow.set_experiment(\u001b[33m'\u001b[39m\u001b[33mbankruptcy-predictions\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    165\u001b[39m mlflow.log_param(\u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m, seed)\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    168\u001b[39m     model = GRUModel(\n\u001b[32m    169\u001b[39m         firm_input_size=firm_input_size,\n\u001b[32m    170\u001b[39m         macro_input_size=macro_input_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    174\u001b[39m         dropout=dropout\n\u001b[32m    175\u001b[39m     )\n\u001b[32m    177\u001b[39m     model = model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/mlflow/tracking/fluent.py:351\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    349\u001b[39m experiment_id = \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    352\u001b[39m         (\n\u001b[32m    353\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    354\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    355\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mrun, call start_run with nested=True\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    356\u001b[39m         ).format(active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    357\u001b[39m     )\n\u001b[32m    358\u001b[39m client = MlflowClient()\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[31mException\u001b[39m: Run with UUID 06653c474f224c5086793f7ff21e61b6 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "train_model_from_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373daf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run painted-wren-983 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/06653c474f224c5086793f7ff21e61b6\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865a5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126a17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric\n",
    "\n",
    "import datetime\n",
    "\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.gru import EnsembleGRU\n",
    "from src.train import train_model\n",
    "from src.utils.utils import collate_with_macro, CustomReduceLROnPlateau, FocalLoss\n",
    "\n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def get_best_models(n_models: int, metric: str = \"val_matthews\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    raw_list = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    runs = raw_list.sort_values(by = \"metrics.\" + metric, ascending = False)\n",
    "    runs.reset_index(inplace=True)\n",
    "    top_runs = runs[:n_models][\"run_id\"]\n",
    "    \n",
    "    model_paths = []\n",
    "    \n",
    "    for run in top_runs:\n",
    "        artifacts = client.list_artifacts(run)\n",
    "        \n",
    "        for artifact in artifacts:\n",
    "            if artifact.is_dir and artifact.path.startswith(\"GRUModel_\"):\n",
    "                model_name = artifact.path\n",
    "                model_uri = f\"runs:/{run}/{model_name}\"\n",
    "                model_paths.append(model_uri)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for model_uri in model_paths:\n",
    "        model = mlflow.pytorch.load_model(model_uri=model_uri)\n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def train(\n",
    "    company_path: str,\n",
    "    macro_paths: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    n_models: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    device: str,\n",
    "    num_layers: int = 2,\n",
    "    hidden_sizes: list[int] = 16,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-2,\n",
    "    train_fract: float = 0.8,\n",
    "    threshold: float = 0.5,\n",
    "    dropout: float = 0.3,\n",
    "    scheduler_factor: float = 0.5,\n",
    "    scheduler_patience: int = 5,\n",
    "    min_lr: float = 1e-5\n",
    "):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level = logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_path=company_path,\n",
    "        macro_paths=macro_paths,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    \n",
    "    ingestion.run()\n",
    "    X, M, y = ingestion.get_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_tensor = M,\n",
    "        labels = y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract=train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # Mac hardware acceleration\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    pos_weight = dataset.pos_weight()\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(\"bankruptcy-predictions\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model_type\", \"ensemble\")\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        \n",
    "        models = get_best_models(n_models=n_models)\n",
    "        for model in models:\n",
    "            model.to(device)\n",
    "        \n",
    "        ensemble_model = EnsembleGRU(\n",
    "            models=models, hidden_sizes=hidden_sizes, threshold=threshold, dropout=dropout\n",
    "        )\n",
    "        ensemble_model = ensemble_model.to(device)\n",
    "        \n",
    "        # loss_fn = FocalLoss(alpha=0.9, gamma=2.5)\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_sizes)\n",
    "        mlflow.log_param(\"num_layers\", len(hidden_sizes))\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        optimizer = Adam(ensemble_model.parameters(), lr = lr)\n",
    "        scheduler=CustomReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        train_model(\n",
    "            model=ensemble_model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics,\n",
    "            stopping_patience=20,\n",
    "            stopping_window=10\n",
    "        )\n",
    "        \n",
    "        mlflow.pytorch.log_model(ensemble_model, f\"model_{datetime.datetime.now()}\")\n",
    "        torch.save(obj = ensemble_model.state_dict(), f = f\"model_{datetime.datetime.now()}.pth\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdc6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.utils import TrainConfig\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> EnsembleGRU:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(cfg.firm_data),\n",
    "        macro_paths = [Path(path) for path in cfg.macro_data],\n",
    "        bankruptcy_col = cfg.bankruptcy_col,\n",
    "        company_col=cfg.company_col,\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        revenue_cap=3000,\n",
    "        n_models=5,\n",
    "        device=cfg.device,\n",
    "        num_layers=cfg.num_classes,\n",
    "        hidden_sizes=[cfg.hidden_size] if isinstance(cfg.hidden_size, int) else cfg.hidden_size,\n",
    "        epochs=cfg.epochs,\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=cfg.train_fract,\n",
    "        dropout=cfg.dropout,\n",
    "        scheduler_factor=cfg.scheduler_factor,\n",
    "        scheduler_patience=cfg.scheduler_patience,\n",
    "        seed=cfg.seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515b0432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/_8tc5upe.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/04locp20.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1928', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/_8tc5upe.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/04locp20.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelc0hbfwgz/prophet_model-20250714203739.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:37:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:37:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/fm6zsts9.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/_xifp_rn.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=89500', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/fm6zsts9.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/_xifp_rn.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model8rb46dpr/prophet_model-20250714203739.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:37:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:37:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/901amwcd.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/kk9mdaxm.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64413', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/901amwcd.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/kk9mdaxm.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelwlaezr0_/prophet_model-20250714203739.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:37:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:37:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae9e3dd17cf439a8314951884c56a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a88f782e99453189b0b119b16984b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9db2ca13fb402ba7f9cdb637625398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Loss: 1.06419 | ACCURACY: 0.89833 | AUROC: 0.76423 | F1: 0.30435 | MATTHEWS: 0.25053 | LR: 0.00375:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [06:06<04:25, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29, restoring model from epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 20:44:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run respected-shark-559 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/cd8f05d0336b40e188b4c1618c8ef3ee\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/46zwvvgi.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/z8eug65p.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=11550', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/46zwvvgi.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/z8eug65p.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model9022l_q7/prophet_model-20250714204408.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:44:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:44:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/78f726n0.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/5ujsrmwt.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=32362', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/78f726n0.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/5ujsrmwt.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelgpcydpk9/prophet_model-20250714204408.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:44:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:44:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/sspzgri5.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/9ol4uxge.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=26566', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/sspzgri5.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/9ol4uxge.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model3wcf3u_m/prophet_model-20250714204408.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:44:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:44:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc868ca32a88400a97e112ac2a44d867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1699800ac1104f3c98722b0fa36c763d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71661b096e9444049d68469d52516455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Loss: 1.09560 | ACCURACY: 0.89496 | AUROC: 0.75411 | F1: 0.30303 | MATTHEWS: 0.24825 | LR: 0.00281:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [06:30<03:59, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31, restoring model from epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 20:50:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run legendary-shoat-447 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/54cb10600a394abd878c16319f4e684f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/6hhkindj.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/0gn1_q08.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=91378', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/6hhkindj.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/0gn1_q08.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model8sssxbwf/prophet_model-20250714205100.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:51:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:51:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/2m57ab7y.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/c7p7cnk5.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63511', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/2m57ab7y.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/c7p7cnk5.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelooboklmk/prophet_model-20250714205100.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:51:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:51:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/f7qlh45v.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7soxcels.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=15604', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/f7qlh45v.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7soxcels.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelhe8ch8ja/prophet_model-20250714205100.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:51:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:51:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6de4a1cf2b34bc18c9897dd2432bc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f38dadf8d1b4d7b98b3bf81b91c74b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Loss: 1.11230 | ACCURACY: 0.89913 | AUROC: 0.73566 | F1: 0.26801 | MATTHEWS: 0.21388 | LR: 0.00281:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [04:11<03:02,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29, restoring model from epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 20:55:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run receptive-pug-234 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/9da52f7cc4ba4d74b9bca4b31db84152\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/n5kznvyu.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/vlw8qima.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=42416', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/n5kznvyu.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/vlw8qima.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelik88niv8/prophet_model-20250714205532.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:55:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:55:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/2h6csn_s.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/cvbyi0rt.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=52415', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/2h6csn_s.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/cvbyi0rt.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model2z4g6m33/prophet_model-20250714205532.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:55:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:55:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/54o9ya28.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/moseho0m.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=27237', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/54o9ya28.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/moseho0m.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modely9pbmnmm/prophet_model-20250714205533.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "20:55:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "20:55:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c475d11c28ff48bfb50dc679675e8cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5726e443b8324f14a6bceb545c2e5d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Loss: 1.09694 | ACCURACY: 0.90389 | AUROC: 0.73988 | F1: 0.28190 | MATTHEWS: 0.23044 | LR: 0.00281:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [04:30<03:00,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30, restoring model from epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:00:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run bedecked-dove-970 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/6af5cd7cc2bd4330891f7c50a2dbcb89\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/ssuej1ji.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/pmo7z56j.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=44673', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/ssuej1ji.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/pmo7z56j.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model88kequqn/prophet_model-20250714210024.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:00:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/tj9qbe3g.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/r2l69b6w.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=34914', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/tj9qbe3g.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/r2l69b6w.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelgig5wnju/prophet_model-20250714210024.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:00:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zm78z10m.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/4sk0utjf.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=40745', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zm78z10m.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/4sk0utjf.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelgp35aesi/prophet_model-20250714210024.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:00:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80da585fc6fe4500a8f6ed6e7d43e774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad20b5f349484b3ea7fdf64a7130026d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Loss: 1.11340 | ACCURACY: 0.89337 | AUROC: 0.73466 | F1: 0.26337 | MATTHEWS: 0.20659 | LR: 0.00500:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [04:19<03:07,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29, restoring model from epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:05:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run learned-cub-710 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/c5862465fdd6477bbfcbc90c989180ce\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zgy4k_sh.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/6tkg1los.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=34401', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zgy4k_sh.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/6tkg1los.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelcj_sy2zb/prophet_model-20250714210504.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:05:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:05:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7_qyrrhd.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/ygbw96nt.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=8475', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7_qyrrhd.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/ygbw96nt.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelah7ot76r/prophet_model-20250714210505.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:05:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:05:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/8t_5wqoy.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/194a1nvj.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=41542', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/8t_5wqoy.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/194a1nvj.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model4rwp2fzk/prophet_model-20250714210505.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:05:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:05:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a94a0147774261bcd462b53e7ca5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e0871d527e447a8e0863cc431f81b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Loss: 1.12255 | ACCURACY: 0.90409 | AUROC: 0.73003 | F1: 0.25348 | MATTHEWS: 0.20279 | LR: 0.00500:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [05:03<02:22,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 34, restoring model from epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:10:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run funny-carp-707 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/de636120bf2144d1bbd56a23306e9417\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/agz8j9ms.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7cc6nknm.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64490', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/agz8j9ms.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/7cc6nknm.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelu4twtpxh/prophet_model-20250714211029.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:10:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:10:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/pw67kqxs.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/1ajdjhpl.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=27185', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/pw67kqxs.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/1ajdjhpl.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelwyhq7s0z/prophet_model-20250714211029.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:10:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:10:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zfsrrvgz.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/mklnr0k5.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=78905', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zfsrrvgz.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/mklnr0k5.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model9h7yg8_f/prophet_model-20250714211030.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:10:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:10:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05841e84b4d42f8acd2f08932c99ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Loss: 1.12473 | ACCURACY: 0.90707 | AUROC: 0.72580 | F1: 0.25949 | MATTHEWS: 0.21109 | LR: 0.00375:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [02:40<01:47,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30, restoring model from epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:13:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run learned-carp-807 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/dfedcc92bc1d4bc2bfdda0221efaa58c\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/hbuy88xq.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zg4nr94w.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=73561', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/hbuy88xq.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/zg4nr94w.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelccrcya_4/prophet_model-20250714211331.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:13:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:13:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/apg7elgb.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/umm9ays2.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=99714', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/apg7elgb.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/umm9ays2.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelvwm80wik/prophet_model-20250714211331.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:13:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:13:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/yvcbv4hg.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/rzalkow8.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=81506', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/yvcbv4hg.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/rzalkow8.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelcszs3m6l/prophet_model-20250714211331.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:13:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:13:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be80b5b0febd47bea3402d6b21423e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Loss: 1.11762 | ACCURACY: 0.89496 | AUROC: 0.73472 | F1: 0.28223 | MATTHEWS: 0.22656 | LR: 0.00281:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/50 [02:48<01:43,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31, restoring model from epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:16:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run nimble-wolf-699 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/ba8e782635364432afb00d167980e432\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/r6_zmp4l.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/v_d_1_h3.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=12886', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/r6_zmp4l.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/v_d_1_h3.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelnl3jk0ov/prophet_model-20250714211648.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:16:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:16:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/okcz1gg4.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/0op92va_.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=20452', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/okcz1gg4.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/0op92va_.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelrvl6qkre/prophet_model-20250714211648.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:16:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:16:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/3ged8hi7.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/5v75z0lz.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=70852', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/3ged8hi7.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/5v75z0lz.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelzsbnlz_s/prophet_model-20250714211648.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:16:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:16:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a251255f8ff40c1ac0da393535886ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Loss: 1.11756 | ACCURACY: 0.89793 | AUROC: 0.73224 | F1: 0.25291 | MATTHEWS: 0.19814 | LR: 0.00281:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [02:56<01:30,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 33, restoring model from epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/14 21:20:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run adaptable-shrike-89 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/d09609ffc3464c07bea2c0cd2d8af002\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/fmz_6ahk.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/8naxrqpd.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=13702', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/fmz_6ahk.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/8naxrqpd.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modelo5np7csk/prophet_model-20250714212005.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:20:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:20:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/nk7bzlkf.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/n3_kv2mm.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=26083', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/nk7bzlkf.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/n3_kv2mm.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_modellpc_p4w3/prophet_model-20250714212005.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:20:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:20:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/jvoz34o0.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/cr8ue9ru.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=77707', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/jvoz34o0.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/cr8ue9ru.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpxitkoibe/prophet_model9kz3umyc/prophet_model-20250714212006.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "21:20:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "21:20:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run zealous-moose-704 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/27298398f5634776a36a62b45030630f\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m     config=yaml.safe_load(stream)\n\u001b[32m      4\u001b[39m     config = TrainConfig(**config)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtrain_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_model_from_config\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model_from_config\u001b[39m(cfg: TrainConfig) -> EnsembleGRU:\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Main training function\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfirm_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_paths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmacro_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevenue_cap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(company_path, macro_paths, bankruptcy_col, company_col, revenue_cap, n_models, metrics, seed, device, num_layers, hidden_sizes, epochs, lr, train_fract, threshold, dropout, scheduler_factor, scheduler_patience, min_lr)\u001b[39m\n\u001b[32m    123\u001b[39m optimizer = Adam(ensemble_model.parameters(), lr = lr)\n\u001b[32m    124\u001b[39m scheduler=CustomReduceLROnPlateau(\n\u001b[32m    125\u001b[39m     optimizer=optimizer,\n\u001b[32m    126\u001b[39m     factor=scheduler_factor,\n\u001b[32m    127\u001b[39m     patience=scheduler_patience,\n\u001b[32m    128\u001b[39m     min_lr=min_lr\n\u001b[32m    129\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensemble_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_window\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m    142\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m mlflow.pytorch.log_model(ensemble_model, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.datetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m torch.save(obj = ensemble_model.state_dict(), f = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.datetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/train.py:81\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimizer, scheduler, stopping_patience, stopping_window, device, epochs, metrics)\u001b[39m\n\u001b[32m     76\u001b[39m early_stopping = RollingEarlyStopping(\n\u001b[32m     77\u001b[39m     patience=stopping_patience, window=stopping_window\n\u001b[32m     78\u001b[39m )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     train_loss, train_metrics = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     last_lr = scheduler.get_last_lr()[\u001b[32m0\u001b[39m]\n\u001b[32m     86\u001b[39m     train_metrics[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m] = last_lr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/train.py:23\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, loss_fn, device, metrics)\u001b[39m\n\u001b[32m     20\u001b[39m labels = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].to(device) \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n\u001b[32m     22\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirm_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmacro_seq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch, 1)\u001b[39;00m\n\u001b[32m     25\u001b[39m loss = loss_fn(preds, labels)\n\u001b[32m     26\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/models/gru.py:158\u001b[39m, in \u001b[36mEnsembleGRU.forward\u001b[39m\u001b[34m(self, firm, macro)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m    156\u001b[39m     raw_logits = [model(firm, macro) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.models]\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m logits_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# (B, n_models, 1)\u001b[39;00m\n\u001b[32m    159\u001b[39m normalized_logits = normalize_logits(logits_tensor)\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# context, _ = self.attn(logits_tensor)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    with open(\"config/model_config.yml\") as stream:\n",
    "        config=yaml.safe_load(stream)\n",
    "        config = TrainConfig(**config)\n",
    "    train_model_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef3b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1afa53709c4c0eb8ca61334be029dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from src.models.gru import GRUModel\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "model_uri = 'runs:/bb5b7d115ac04197a760a5d7aba049e9/GRUModel_20250701_233333'\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b840dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d17982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.train_matthews</th>\n",
       "      <th>metrics.best_threshold</th>\n",
       "      <th>metrics.best_f1</th>\n",
       "      <th>metrics.train_lr</th>\n",
       "      <th>...</th>\n",
       "      <th>params.hidden_size</th>\n",
       "      <th>params.num_layers</th>\n",
       "      <th>params.output_size</th>\n",
       "      <th>tags.mlflow.log-model.history</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.model_type</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.ensemble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6cdacabfdbf644019d2c147256818dd5</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/6cdacabfd...</td>\n",
       "      <td>2025-07-14 12:24:37.989000+00:00</td>\n",
       "      <td>2025-07-14 12:42:00.901000+00:00</td>\n",
       "      <td>0.071489</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.340249</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>...</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"run_id\": \"6cdacabfdbf644019d2c147256818dd5\"...</td>\n",
       "      <td>chill-hound-382</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>/Users/guillaumedecina-halmi/miniforge3/lib/py...</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>805f7855e48b4ac8939d4959d54efb0e</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/805f7855e...</td>\n",
       "      <td>2025-07-14 12:10:09.239000+00:00</td>\n",
       "      <td>2025-07-14 12:24:28.802000+00:00</td>\n",
       "      <td>0.067752</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>...</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"run_id\": \"805f7855e48b4ac8939d4959d54efb0e\"...</td>\n",
       "      <td>silent-finch-41</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>/Users/guillaumedecina-halmi/miniforge3/lib/py...</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0a7b61714e52426da980dcaaa94a24b7</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/0a7b61714...</td>\n",
       "      <td>2025-07-14 11:59:04.549000+00:00</td>\n",
       "      <td>2025-07-14 12:09:11.246000+00:00</td>\n",
       "      <td>-0.048402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>dapper-crab-958</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>/Users/guillaumedecina-halmi/miniforge3/lib/py...</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d788cea214014ceabbab6c592c0cdef4</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/d788cea21...</td>\n",
       "      <td>2025-07-14 11:56:36.312000+00:00</td>\n",
       "      <td>2025-07-14 11:56:42.762000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[64, 32, 16]</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>inquisitive-midge-0</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>/Users/guillaumedecina-halmi/miniforge3/lib/py...</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f51c4836b994542b500e3bae383105e</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/8f51c4836...</td>\n",
       "      <td>2025-07-14 11:55:07.056000+00:00</td>\n",
       "      <td>2025-07-14 11:55:13.686000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>powerful-asp-432</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>/Users/guillaumedecina-halmi/miniforge3/lib/py...</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>a5ef4ae82b974f178db362043a06f378</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/a5ef4ae82...</td>\n",
       "      <td>2025-04-03 16:17:27.379000+00:00</td>\n",
       "      <td>2025-04-03 16:17:35.267000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"run_id\": \"a5ef4ae82b974f178db362043a06f378\"...</td>\n",
       "      <td>wise-boar-183</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "      <td>/Users/guillaumedecina-halmi/Library/Python/3....</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>4acbec115384493d846cb0cf25f07b0c</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/4acbec115...</td>\n",
       "      <td>2025-04-03 16:16:10.017000+00:00</td>\n",
       "      <td>2025-04-03 16:16:10.070000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>welcoming-stork-436</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "      <td>/Users/guillaumedecina-halmi/Library/Python/3....</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>a318ac43d95d474595373f042d3efc0d</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/a318ac43d...</td>\n",
       "      <td>2025-04-03 16:15:02.037000+00:00</td>\n",
       "      <td>2025-04-03 16:15:02.096000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>classy-donkey-176</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "      <td>/Users/guillaumedecina-halmi/Library/Python/3....</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>4e3239ab510142ab9b5dc6c04ace7e95</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/4e3239ab5...</td>\n",
       "      <td>2025-04-03 16:14:30.895000+00:00</td>\n",
       "      <td>2025-04-03 16:14:33.204000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>mysterious-midge-268</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "      <td>/Users/guillaumedecina-halmi/Library/Python/3....</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>f140ac4ce4f54ce18fbd3048c6ffc6f2</td>\n",
       "      <td>387584985157093548</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mlflow-artifacts:/387584985157093548/f140ac4ce...</td>\n",
       "      <td>2025-04-03 16:12:23.896000+00:00</td>\n",
       "      <td>2025-04-03 16:12:26.728000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>worried-lynx-316</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "      <td>/Users/guillaumedecina-halmi/Library/Python/3....</td>\n",
       "      <td>guillaumedecina-halmi</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1035 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id       experiment_id    status  \\\n",
       "0     6cdacabfdbf644019d2c147256818dd5  387584985157093548  FINISHED   \n",
       "1     805f7855e48b4ac8939d4959d54efb0e  387584985157093548  FINISHED   \n",
       "2     0a7b61714e52426da980dcaaa94a24b7  387584985157093548    FAILED   \n",
       "3     d788cea214014ceabbab6c592c0cdef4  387584985157093548    FAILED   \n",
       "4     8f51c4836b994542b500e3bae383105e  387584985157093548    FAILED   \n",
       "...                                ...                 ...       ...   \n",
       "1030  a5ef4ae82b974f178db362043a06f378  387584985157093548  FINISHED   \n",
       "1031  4acbec115384493d846cb0cf25f07b0c  387584985157093548    FAILED   \n",
       "1032  a318ac43d95d474595373f042d3efc0d  387584985157093548    FAILED   \n",
       "1033  4e3239ab510142ab9b5dc6c04ace7e95  387584985157093548    FAILED   \n",
       "1034  f140ac4ce4f54ce18fbd3048c6ffc6f2  387584985157093548    FAILED   \n",
       "\n",
       "                                           artifact_uri  \\\n",
       "0     mlflow-artifacts:/387584985157093548/6cdacabfd...   \n",
       "1     mlflow-artifacts:/387584985157093548/805f7855e...   \n",
       "2     mlflow-artifacts:/387584985157093548/0a7b61714...   \n",
       "3     mlflow-artifacts:/387584985157093548/d788cea21...   \n",
       "4     mlflow-artifacts:/387584985157093548/8f51c4836...   \n",
       "...                                                 ...   \n",
       "1030  mlflow-artifacts:/387584985157093548/a5ef4ae82...   \n",
       "1031  mlflow-artifacts:/387584985157093548/4acbec115...   \n",
       "1032  mlflow-artifacts:/387584985157093548/a318ac43d...   \n",
       "1033  mlflow-artifacts:/387584985157093548/4e3239ab5...   \n",
       "1034  mlflow-artifacts:/387584985157093548/f140ac4ce...   \n",
       "\n",
       "                           start_time                         end_time  \\\n",
       "0    2025-07-14 12:24:37.989000+00:00 2025-07-14 12:42:00.901000+00:00   \n",
       "1    2025-07-14 12:10:09.239000+00:00 2025-07-14 12:24:28.802000+00:00   \n",
       "2    2025-07-14 11:59:04.549000+00:00 2025-07-14 12:09:11.246000+00:00   \n",
       "3    2025-07-14 11:56:36.312000+00:00 2025-07-14 11:56:42.762000+00:00   \n",
       "4    2025-07-14 11:55:07.056000+00:00 2025-07-14 11:55:13.686000+00:00   \n",
       "...                               ...                              ...   \n",
       "1030 2025-04-03 16:17:27.379000+00:00 2025-04-03 16:17:35.267000+00:00   \n",
       "1031 2025-04-03 16:16:10.017000+00:00 2025-04-03 16:16:10.070000+00:00   \n",
       "1032 2025-04-03 16:15:02.037000+00:00 2025-04-03 16:15:02.096000+00:00   \n",
       "1033 2025-04-03 16:14:30.895000+00:00 2025-04-03 16:14:33.204000+00:00   \n",
       "1034 2025-04-03 16:12:23.896000+00:00 2025-04-03 16:12:26.728000+00:00   \n",
       "\n",
       "      metrics.train_matthews  metrics.best_threshold  metrics.best_f1  \\\n",
       "0                   0.071489                     0.5         0.340249   \n",
       "1                   0.067752                     0.5         0.303571   \n",
       "2                  -0.048402                     NaN              NaN   \n",
       "3                        NaN                     NaN              NaN   \n",
       "4                        NaN                     NaN              NaN   \n",
       "...                      ...                     ...              ...   \n",
       "1030                     NaN                     NaN              NaN   \n",
       "1031                     NaN                     NaN              NaN   \n",
       "1032                     NaN                     NaN              NaN   \n",
       "1033                     NaN                     NaN              NaN   \n",
       "1034                     NaN                     NaN              NaN   \n",
       "\n",
       "      metrics.train_lr  ...  params.hidden_size  params.num_layers  \\\n",
       "0             0.005625  ...        [64, 32, 16]                  2   \n",
       "1             0.005625  ...        [64, 32, 16]                  2   \n",
       "2             0.010000  ...        [64, 32, 16]                  2   \n",
       "3                  NaN  ...        [64, 32, 16]                  2   \n",
       "4                  NaN  ...                None               None   \n",
       "...                ...  ...                 ...                ...   \n",
       "1030               NaN  ...                None               None   \n",
       "1031               NaN  ...                None               None   \n",
       "1032               NaN  ...                None               None   \n",
       "1033               NaN  ...                None               None   \n",
       "1034               NaN  ...                None               None   \n",
       "\n",
       "      params.output_size                      tags.mlflow.log-model.history  \\\n",
       "0                   None  [{\"run_id\": \"6cdacabfdbf644019d2c147256818dd5\"...   \n",
       "1                   None  [{\"run_id\": \"805f7855e48b4ac8939d4959d54efb0e\"...   \n",
       "2                   None                                               None   \n",
       "3                   None                                               None   \n",
       "4                   None                                               None   \n",
       "...                  ...                                                ...   \n",
       "1030                None  [{\"run_id\": \"a5ef4ae82b974f178db362043a06f378\"...   \n",
       "1031                None                                               None   \n",
       "1032                None                                               None   \n",
       "1033                None                                               None   \n",
       "1034                None                                               None   \n",
       "\n",
       "       tags.mlflow.runName  tags.mlflow.source.type  tags.model_type  \\\n",
       "0          chill-hound-382                    LOCAL         ensemble   \n",
       "1          silent-finch-41                    LOCAL         ensemble   \n",
       "2          dapper-crab-958                    LOCAL         ensemble   \n",
       "3      inquisitive-midge-0                    LOCAL         ensemble   \n",
       "4         powerful-asp-432                    LOCAL         ensemble   \n",
       "...                    ...                      ...              ...   \n",
       "1030         wise-boar-183                    LOCAL             None   \n",
       "1031   welcoming-stork-436                    LOCAL             None   \n",
       "1032     classy-donkey-176                    LOCAL             None   \n",
       "1033  mysterious-midge-268                    LOCAL             None   \n",
       "1034      worried-lynx-316                    LOCAL             None   \n",
       "\n",
       "                                tags.mlflow.source.name  \\\n",
       "0     /Users/guillaumedecina-halmi/miniforge3/lib/py...   \n",
       "1     /Users/guillaumedecina-halmi/miniforge3/lib/py...   \n",
       "2     /Users/guillaumedecina-halmi/miniforge3/lib/py...   \n",
       "3     /Users/guillaumedecina-halmi/miniforge3/lib/py...   \n",
       "4     /Users/guillaumedecina-halmi/miniforge3/lib/py...   \n",
       "...                                                 ...   \n",
       "1030  /Users/guillaumedecina-halmi/Library/Python/3....   \n",
       "1031  /Users/guillaumedecina-halmi/Library/Python/3....   \n",
       "1032  /Users/guillaumedecina-halmi/Library/Python/3....   \n",
       "1033  /Users/guillaumedecina-halmi/Library/Python/3....   \n",
       "1034  /Users/guillaumedecina-halmi/Library/Python/3....   \n",
       "\n",
       "           tags.mlflow.user  tags.ensemble  \n",
       "0     guillaumedecina-halmi           None  \n",
       "1     guillaumedecina-halmi           None  \n",
       "2     guillaumedecina-halmi           None  \n",
       "3     guillaumedecina-halmi           None  \n",
       "4     guillaumedecina-halmi           None  \n",
       "...                     ...            ...  \n",
       "1030  guillaumedecina-halmi           None  \n",
       "1031  guillaumedecina-halmi           None  \n",
       "1032  guillaumedecina-halmi           None  \n",
       "1033  guillaumedecina-halmi           None  \n",
       "1034  guillaumedecina-halmi           None  \n",
       "\n",
       "[1035 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs = runs.sort_values(by = \"metrics.val_matthews\", ascending = False)[:7]\n",
    "selected_runs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01661e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04083ac7e0e4e7293a6c9f693b24713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpux7aooyn/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.artifacts\n",
    "\n",
    "\n",
    "mlflow.artifacts.download_artifacts(run_id=\"fe05629c8fa04c18a6e37553051db968\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0d7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'run_id', 'experiment_id', 'status', 'artifact_uri',\n",
       "       'start_time', 'end_time', 'metrics.train_matthews',\n",
       "       'metrics.best_threshold', 'metrics.best_f1', 'metrics.train_lr',\n",
       "       'metrics.val_auroc', 'metrics.train_accuracy', 'metrics.val_accuracy',\n",
       "       'metrics.val_matthews', 'metrics.train_f1', 'metrics.val_loss',\n",
       "       'metrics.train_auroc', 'metrics.val_f1',\n",
       "       'metrics.val_BinaryMatthewsCorrCoef', 'metrics.val_BinaryF1Score',\n",
       "       'metrics.val_BinaryRecall', 'metrics.train_BinaryRecall',\n",
       "       'metrics.val_BinaryPrecision', 'metrics.train_BinaryAveragePrecision',\n",
       "       'metrics.train_BinaryF1Score', 'metrics.train_BinaryPrecision',\n",
       "       'metrics.train_BinaryMatthewsCorrCoef',\n",
       "       'metrics.val_BinaryAveragePrecision', 'metrics.train_BinaryAUROC',\n",
       "       'metrics.val_BinaryAUROC', 'metrics.auc', 'metrics.lr', 'metrics.f1',\n",
       "       'metrics.loss', 'params.lr', 'params.seed', 'params.dropout',\n",
       "       'params.hidden_size', 'params.num_layers', 'params.output_size',\n",
       "       'tags.mlflow.log-model.history', 'tags.mlflow.runName',\n",
       "       'tags.mlflow.source.type', 'tags.model_type', 'tags.mlflow.source.name',\n",
       "       'tags.mlflow.user', 'tags.ensemble'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a1d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mlflow-artifacts:/387584985157093548/fe05629c8fa04c18a6e37553051db968/artifacts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_runs[\"artifact_uri\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680cc2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m run = \u001b[43mrun_ids\u001b[49m[\u001b[32m89\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'run_ids' is not defined"
     ]
    }
   ],
   "source": [
    "run = run_ids[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae462131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64080353",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.pytorch.load_model(\"runs:/bb5b7d115ac04197a760a5d7aba049e9/GRUModel_20250701_233333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_paths = []\n",
    "artifacts = client.list_artifacts(run_ids[89])\n",
    "for artifact in artifacts:\n",
    "    if artifact.is_dir and artifact.path.starts_with(\"GRUModel_\"):\n",
    "        model_name = artifact.path\n",
    "        model_uri = f\"runs/.../{model_name}\"\n",
    "        model_paths.append((run.infomodel_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def get_best_models(n_models: int = 7, metric: str = \"val_matthews\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    selected_runs = runs.sort_values(by = \"metrics.\" + metric, ascending = False)[:n_models][\"run_id\"]\n",
    "    selected_runs.reset_index(inplace=True)\n",
    "    \n",
    "    model_paths = []\n",
    "    \n",
    "    for run in selected_runs:\n",
    "        run_id = run.info.run_id\n",
    "        artifacts = client.list_artifacts(run_id)\n",
    "        \n",
    "        for artifact in artifacts:\n",
    "            if artifact.is_dir and artifact.path.starts_with(\"GRUModel_\"):\n",
    "                model_name = artifact.path\n",
    "                model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "                model_paths.append(model_uri)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for model_uri in model_paths:\n",
    "        model = mlflow.pytorch.load_model(model_uri = model_uri)\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef740f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_best_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "selected_runs = runs.sort_values(by = \"metrics.val_matthews\", ascending = False)[:7][\"tags.mlflow.log-model.history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027daea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(selected_runs[101], r\"\\\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1be063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(n_models: int = 7, metric: str = \"val_matthews\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    selected_runs = runs.sort_values(by = \"metrics.\" + metric, ascending = False)[:n_models][\"run_id\"]\n",
    "    for run in selected_runs:\n",
    "        model_uri = \"runs:/\" + run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71398988",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f76a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to base (Python 3.12.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20475a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "import datetime\n",
    "import logging\n",
    "import yaml\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.tft import TFTModel\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.train.tft import train_tft\n",
    "from src.utils.utils import TrainConfig, FocalLoss\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> TFTModel:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(\"../\" + cfg.firm_data),\n",
    "        macro_paths = [str(id) for id in cfg.macro_data],\n",
    "        bankruptcy_col = str(cfg.bankruptcy_col),\n",
    "        company_col=str(cfg.company_col),\n",
    "        revenue_cap=int(cfg.revenue_cap),\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        device=str(cfg.device),\n",
    "        hidden_size=int(cfg.hidden_size),\n",
    "        output_size=1,\n",
    "        epochs=int(cfg.epochs),\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=float(cfg.train_fract),\n",
    "        dropout=int(cfg.dropout),\n",
    "        alpha=float(cfg.alpha),\n",
    "        gamma=float(cfg.alpha),\n",
    "        scheduler_factor=float(cfg.scheduler_factor),\n",
    "        scheduler_patience=int(cfg.scheduler_patience),\n",
    "        stopping_patience=int(cfg.stopping_patience),\n",
    "        seed=int(cfg.seed)\n",
    "    )\n",
    "\n",
    "def train(\n",
    "    company_path: str,\n",
    "    macro_paths: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    num_layers: int = 2,\n",
    "    hidden_size: int = 64,\n",
    "    output_size: int = 1,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-3,\n",
    "    train_fract: float = 0.8,\n",
    "    dropout: float = 0.2,\n",
    "    alpha: float = 0.9,\n",
    "    gamma: float = 2.0,\n",
    "    scheduler_factor: float = 0.85,\n",
    "    scheduler_patience: int = 50,\n",
    "    stopping_patience: int = 10,\n",
    "    stopping_window: int = 5,\n",
    "    min_lr: float = 0.0,\n",
    "    device: str=\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "):  \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_path=company_path,\n",
    "        macro_paths=macro_paths,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    \n",
    "    ingestion.run()\n",
    "    X, M_past, M_future, y = ingestion.get_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_past_tensor = M_past,\n",
    "        macro_future_tensor = M_future,\n",
    "        labels = y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    metrics.to(device)\n",
    "    train_ds = train_ds.to_device(device)\n",
    "    val_ds = val_ds.to_device(device)\n",
    "    \n",
    "    firm_input_size, macro_past_input_size, macro_future_input_size = dataset.input_dims()\n",
    "    firm_input_size = firm_input_size[-1]\n",
    "    macro_past_input_size = macro_past_input_size[-1]\n",
    "    macro_future_input_size = macro_future_input_size[-1]\n",
    "    \n",
    "    mlflow.set_tracking_uri('http://127.0.0.1:8080')\n",
    "    mlflow.set_experiment('bankruptcy-predictions')\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model_type\", \"tft\")\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        model = TFTModel(\n",
    "            static_input_dim=0,\n",
    "            company_input_dim=firm_input_size,\n",
    "            macro_input_dim=macro_past_input_size,\n",
    "            decoder_input_dim=macro_future_input_size,\n",
    "            hidden_dim=hidden_size,\n",
    "            attention_heads=4,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        pos_weight = dataset.pos_weight()\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        \n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_size)\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "        scheduler=ReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        \n",
    "        train_tft(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            stopping_patience=stopping_patience,\n",
    "            stopping_window=stopping_window,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        model_name = f\"TFTModel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        mlflow.pytorch.log_model(model, model_name)\n",
    "        torch.save(obj = model.state_dict(), f = f\"../models/{model_name}.pth\")\n",
    "        print(f\"Model saved: {model_name}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbeee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = load_yaml_file(\"../config/tft_config.yml\")\n",
    "cfg = TrainConfig(**config_dict)\n",
    "\n",
    "company_data_path = Path(\"../\" + cfg.firm_data)\n",
    "macro_data_path = [str(id) for id in cfg.macro_data]\n",
    "bankruptcy_col = str(cfg.bankruptcy_col)\n",
    "company_col=str(cfg.company_col)\n",
    "revenue_cap=int(cfg.revenue_cap)\n",
    "metrics=cfg.get_metrics().to(cfg.device)\n",
    "device=str(cfg.device)\n",
    "num_layers=int(cfg.num_classes)\n",
    "hidden_size=int(cfg.hidden_size)\n",
    "output_size=1\n",
    "epochs=int(cfg.epochs)\n",
    "lr=float(cfg.lr)\n",
    "train_fract=float(cfg.train_fract)\n",
    "dropout=int(cfg.dropout)\n",
    "scheduler_factor=float(cfg.scheduler_factor)\n",
    "scheduler_patience=int(cfg.scheduler_patience)\n",
    "seed=int(cfg.seed)\n",
    "\n",
    "ingestion = IngestionPipeline(\n",
    "    company_path=company_data_path,\n",
    "    macro_paths=macro_data_path,\n",
    "    company_col=company_col,\n",
    "    bankruptcy_col=bankruptcy_col,\n",
    "    revenue_cap=revenue_cap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615f8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data2.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "ERROR:root:Training failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py\", line 92, in _clean\n",
      "    df[self.bankruptcy_col] = pd.to_datetime(\n",
      "                              ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py\", line 1067, in to_datetime\n",
      "    values = convert_listlike(arg._values, format)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py\", line 407, in _convert_listlike_datetimes\n",
      "    return _to_datetime_with_unit(arg, unit, name, utc, errors)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/pandas/core/tools/datetimes.py\", line 512, in _to_datetime_with_unit\n",
      "    arr = cast_from_unit_vectorized(arg, unit=unit)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"conversion.pyx\", line 149, in pandas._libs.tslibs.conversion.cast_from_unit_vectorized\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/numpy/core/fromnumeric.py\", line 3360, in round\n",
      "    return _wrapfunc(a, 'round', decimals=decimals, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/numpy/core/fromnumeric.py\", line 59, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "FloatingPointError: overflow encountered in multiply\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/1508587816.py\", line 3, in <module>\n",
      "    model = train_model_from_config(cfg)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/2422658074.py\", line 46, in train_model_from_config\n",
      "    return train(\n",
      "           ^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/2422658074.py\", line 103, in train\n",
      "    ingestion.run()\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/pipeline.py\", line 41, in run\n",
      "    company_df = self.company_loader.load(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py\", line 43, in load\n",
      "    df = self._clean(df)\n",
      "         ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py\", line 108, in _clean\n",
      "    raise RuntimeError(f\"Failed to process data after {max_attempts} attempts\")\n",
      "RuntimeError: Failed to process data after 10 attempts\n",
      "INFO:src.data.loaders:Reading file: ../data/demo_data2.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Applying feature engineering...\n",
      "INFO:src.data.feature_engineer:Fitting feature engineer...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/010774417\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001763782\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001587668\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Financial data tensor shape: (6318, 3, 13)\n",
      "INFO:src.data.tensor_factory:Converting macroeconomic series to tensors...\n",
      "INFO:src.data.tensor_factory:Macro data tensor shape: torch.Size([3, 43]) (past), torch.Size([3, 12]) (future)\n",
      "INFO:__main__:Device: mps\n",
      "ERROR:root:Training failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/1508587816.py\", line 3, in <module>\n",
      "    model = train_model_from_config(cfg)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/2422658074.py\", line 46, in train_model_from_config\n",
      "    return train(\n",
      "           ^^^^^^\n",
      "  File \"/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_59001/2422658074.py\", line 131, in train\n",
      "    with mlflow.start_run():\n",
      "         ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/tracking/fluent.py\", line 444, in start_run\n",
      "    resolved_tags = context_registry.resolve_tags(user_specified_tags)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/tracking/context/registry.py\", line 90, in resolve_tags\n",
      "    if provider.in_context():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/tracking/context/git_context.py\", line 29, in in_context\n",
      "    return self._source_version is not None\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/tracking/context/git_context.py\", line 25, in _source_version\n",
      "    self._cache[\"source_version\"] = _get_source_version()\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/tracking/context/git_context.py\", line 14, in _get_source_version\n",
      "    return get_git_commit(main_file)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/mlflow/utils/git_utils.py\", line 48, in get_git_commit\n",
      "    repo = Repo(path, search_parent_directories=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/git/repo/base.py\", line 218, in __init__\n",
      "    if Git.is_cygwin():\n",
      "       ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/git/cmd.py\", line 664, in is_cygwin\n",
      "    return is_cygwin_git(cls.GIT_PYTHON_GIT_EXECUTABLE)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/git/util.py\", line 492, in is_cygwin_git\n",
      "    return _is_cygwin_git(str(git_executable))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/git/util.py\", line 468, in _is_cygwin_git\n",
      "    uname_out, _ = process.communicate()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/subprocess.py\", line 1198, in communicate\n",
      "    stdout = self.stdout.read()\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past: torch.Size([3, 43]), Future: torch.Size([3, 12])\n",
      "Data sent to device: mps\n",
      "Data sent to device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data2.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Applying feature engineering...\n",
      "INFO:src.data.feature_engineer:Fitting feature engineer...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/010774417\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001763782\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/sdmx/rest/common.py:367: UserWarning: 'agency_id' argument is redundant for data queries\n",
      "  getattr(self, f\"handle_{query_type}\")()\n",
      "INFO:sdmx.client:Request https://www.bdm.insee.fr/series/sdmx/data/SERIES_BDM/001587668\n",
      "INFO:sdmx.client:with headers {'User-Agent': 'python-requests/2.32.3', 'Accept-Encoding': 'gzip, deflate, br, zstd', 'Accept': 'application/vnd.sdmx.genericdata+xml;version=2.1', 'Connection': 'keep-alive'}\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Financial data tensor shape: (6318, 3, 13)\n",
      "INFO:src.data.tensor_factory:Converting macroeconomic series to tensors...\n",
      "INFO:src.data.tensor_factory:Macro data tensor shape: torch.Size([3, 43]) (past), torch.Size([3, 12]) (future)\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past: torch.Size([3, 43]), Future: torch.Size([3, 12])\n",
      "Data sent to device: mps\n",
      "Data sent to device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    try:\n",
    "        model = train_model_from_config(cfg)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.mps.empty_cache()\n",
    "    except:\n",
    "        logging.error(\"Training failed.\", exc_info=True)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.insee import get_insee_series\n",
    "from src.data.time_series import MacroTimeSeries\n",
    "\n",
    "id = \"010774417\"\n",
    "\n",
    "series = get_insee_series(id)\n",
    "mts = MacroTimeSeries(series, [2022, 2023, 2024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea5745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts.forecast_prophet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts.past_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a43983",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts.future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts._forecast(method=\"prophet\", n_periods=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.data.loaders import CompanyDataLoader\n",
    "\n",
    "cdl = CompanyDataLoader(\"../data/demo_data2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cb8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cdl.load(bankruptcy_col=\"Status date\", company_col=\"Company name Latin alphabet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f86f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eebf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

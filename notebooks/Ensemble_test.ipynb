{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Metric\n",
    "\n",
    "import datetime\n",
    "\n",
    "from src.data.pipeline import IngestionPipeline\n",
    "from src.datasets.dual_input import DualInputSequenceDataset\n",
    "from src.models.gru import EnsembleGRU\n",
    "from src.train import train_model\n",
    "from src.utils.utils import collate_with_macro, CustomReduceLROnPlateau, FocalLoss\n",
    "\n",
    "import logging\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def get_best_models(n_models: int, metric: str = \"best_f1\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    raw_list = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    runs = raw_list.sort_values(by = \"metrics.\" + metric, ascending = False)\n",
    "    runs.reset_index(inplace=True)\n",
    "    run_ids = runs[\"run_id\"]\n",
    "    \n",
    "    models = []\n",
    "    current_pool = 0\n",
    "    \n",
    "    for run in run_ids:\n",
    "        try:\n",
    "            artifacts = client.list_artifacts(run)\n",
    "            for artifact in artifacts:\n",
    "                if artifact.is_dir and artifact.path.startswith(\"GRUModel_\"):\n",
    "                    model_name = artifact.path\n",
    "                    model_uri = f\"runs:/{run}/{model_name}\"\n",
    "                    print(f\"Loading model: {model_uri}\")\n",
    "                    model = mlflow.pytorch.load_model(model_uri=model_uri)\n",
    "                    models.append(model)\n",
    "                    \n",
    "                    current_pool += 1\n",
    "                    if current_pool == n_models:\n",
    "                        print(f\"Retrieved {len(models)} models.\")\n",
    "                        return models\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping run {run} due to error: {e}\")\n",
    "    \n",
    "    print(f\"Retrieved {len(models)} models.\")\n",
    "    return models\n",
    "\n",
    "def train(\n",
    "    company_path: str,\n",
    "    macro_paths: list[str],\n",
    "    bankruptcy_col: str,\n",
    "    company_col: str,\n",
    "    revenue_cap: int,\n",
    "    n_models: int,\n",
    "    metrics: list[Metric],\n",
    "    seed: int,\n",
    "    device: str,\n",
    "    num_layers: int = 2,\n",
    "    hidden_sizes: list[int] = 16,\n",
    "    epochs: int = 50,\n",
    "    lr: float = 1e-2,\n",
    "    train_fract: float = 0.8,\n",
    "    threshold: float = 0.5,\n",
    "    dropout: float = 0.3,\n",
    "    scheduler_factor: float = 0.5,\n",
    "    scheduler_patience: int = 5,\n",
    "    min_lr: float = 1e-5\n",
    "):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level = logging.INFO)\n",
    "    \n",
    "    ingestion = IngestionPipeline(\n",
    "        company_path=company_path,\n",
    "        macro_paths=macro_paths,\n",
    "        company_col=company_col,\n",
    "        bankruptcy_col=bankruptcy_col,\n",
    "        revenue_cap=revenue_cap\n",
    "    )\n",
    "    \n",
    "    ingestion.run()\n",
    "    X, M, y = ingestion.get_tensors()\n",
    "    \n",
    "    dataset = DualInputSequenceDataset(\n",
    "        firm_tensor = X,\n",
    "        macro_tensor = M,\n",
    "        labels = y\n",
    "    )\n",
    "    \n",
    "    train_ds, val_ds, seed = dataset.stratified_split(train_fract=train_fract)\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32, shuffle=True, collate_fn=collate_with_macro)\n",
    "\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") # Mac hardware acceleration\n",
    "    logger.info(f\"Device: {device}\")\n",
    "    \n",
    "    pos_weight = dataset.pos_weight()\n",
    "    \n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    mlflow.set_experiment(\"bankruptcy-predictions\")\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model_type\", \"ensemble\")\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        \n",
    "        models = get_best_models(n_models=n_models)\n",
    "        for model in models:\n",
    "            model.to(device)\n",
    "        \n",
    "        ensemble_model = EnsembleGRU(\n",
    "            models=models, hidden_sizes=hidden_sizes, threshold=threshold, dropout=dropout\n",
    "        )\n",
    "        ensemble_model = ensemble_model.to(device)\n",
    "        \n",
    "        # loss_fn = FocalLoss(alpha=0.9, gamma=2.5)\n",
    "        loss_fn = BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        # Logging hyperparameters\n",
    "        mlflow.log_param(\"hidden_size\", hidden_sizes)\n",
    "        mlflow.log_param(\"num_layers\", len(hidden_sizes))\n",
    "        mlflow.log_param(\"dropout\", dropout)\n",
    "        mlflow.log_param(\"lr\", lr)\n",
    "        \n",
    "        optimizer = Adam(ensemble_model.parameters(), lr = lr)\n",
    "        scheduler=CustomReduceLROnPlateau(\n",
    "            optimizer=optimizer,\n",
    "            factor=scheduler_factor,\n",
    "            patience=scheduler_patience,\n",
    "            min_lr=min_lr\n",
    "        )\n",
    "        train_model(\n",
    "            model=ensemble_model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            epochs=epochs,\n",
    "            metrics=metrics,\n",
    "            stopping_patience=20,\n",
    "            stopping_window=10\n",
    "        )\n",
    "        \n",
    "        model_name = f\"EnsembleModel_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        mlflow.pytorch.log_model(model, model_name)\n",
    "        torch.save(obj = model.state_dict(), f = f\"../models/{model_name}.pth\")\n",
    "        print(f\"Model saved: {model_name}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cdc6665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.utils import TrainConfig\n",
    "\n",
    "def load_yaml_file(path):\n",
    "    with open(path) as stream:\n",
    "        try:\n",
    "            config_dict=yaml.safe_load(stream)\n",
    "            return config_dict\n",
    "        except yaml.YAMLError as e:\n",
    "            TypeError(f\"Config file could not be loaded: {e}\")\n",
    "    \n",
    "def train_model_from_config(cfg: TrainConfig) -> EnsembleGRU:\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    return train(\n",
    "        company_path = Path(\"../\" + cfg.firm_data),\n",
    "        macro_paths = [Path(\"../\" + path) for path in cfg.macro_data],\n",
    "        bankruptcy_col = cfg.bankruptcy_col,\n",
    "        company_col=cfg.company_col,\n",
    "        metrics=cfg.get_metrics().to(cfg.device),\n",
    "        revenue_cap=3000,\n",
    "        n_models=7,\n",
    "        device=cfg.device,\n",
    "        num_layers=cfg.num_classes,\n",
    "        hidden_sizes=[cfg.hidden_size] if isinstance(cfg.hidden_size, int) else cfg.hidden_size,\n",
    "        epochs=cfg.epochs,\n",
    "        lr=float(cfg.lr),\n",
    "        train_fract=cfg.train_fract,\n",
    "        dropout=cfg.dropout,\n",
    "        scheduler_factor=cfg.scheduler_factor,\n",
    "        scheduler_patience=cfg.scheduler_patience,\n",
    "        seed=cfg.seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515b0432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/1deusn4h.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/fore3s8t.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=56877', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/1deusn4h.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/fore3s8t.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelf5rgfubl/prophet_model-20250724105954.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "10:59:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "10:59:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/nrqv3a5v.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/rjpjskxc.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=60301', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/nrqv3a5v.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/rjpjskxc.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelphtw3n3b/prophet_model-20250724105954.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "10:59:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "10:59:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/bbqdkkh5.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/tvlhg2ln.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=64658', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/bbqdkkh5.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/tvlhg2ln.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modeln722c_7l/prophet_model-20250724105954.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "10:59:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:00:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f23b8ed7cd1b422fba1cb1a7289c1b12/GRUModel_20250724_061750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ba153d6f5244c590e1ea51170fb2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f1269821006f477d8424259e3ada789c/GRUModel_20250723_224211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a4f128278c4b91a177d22fe5429ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2d8ca5d28d58486daf85ed77074301e5/GRUModel_20250724_102840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b605bcf911a4ab2bceecab8e4f4f92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/ffbe042b627b4877aa32198a422e8dfa/GRUModel_20250724_065920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3439b38e2c47a78caceb6f5caa234a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/7d88e80a8aac4cea99184cee4072d3aa/GRUModel_20250723_203657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c060facd47947ffb7b929d5ace70307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/c6eba5f871c04869aa6b249adb9d368d/GRUModel_20250723_223300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1bb934754f4dc9972b40d466d9d602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2a70998b91a6404fa5e9522dee1e45fc/GRUModel_20250723_205917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930369c65f084360ab1861e5069d6abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Loss: 1.15228 | ACCURACY: 0.62609 | AUROC: 0.71341 | F1: 0.19906 | MATTHEWS: 0.15726 | LR: 0.00281:  62%|██████▏   | 31/50 [15:36<09:33, 30.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31, restoring model from epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/24 11:15:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run stylish-gull-327 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/dae896b8cfe248d1a40016a9ef691c00\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d6pgk1_q.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/2ramvdrv.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=10714', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d6pgk1_q.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/2ramvdrv.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_model2vahzes3/prophet_model-20250724111548.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:15:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:15:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d6migg0o.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/q66qcqxu.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=39511', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d6migg0o.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/q66qcqxu.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelk6yr5p_7/prophet_model-20250724111549.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:15:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:15:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/2gikpjp9.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/vblavwo3.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=34694', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/2gikpjp9.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/vblavwo3.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_model1l624ck4/prophet_model-20250724111549.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:15:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:15:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f23b8ed7cd1b422fba1cb1a7289c1b12/GRUModel_20250724_061750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffba554a65241b79830e7f44cc9b9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f1269821006f477d8424259e3ada789c/GRUModel_20250723_224211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6583ceecb9ad492ab071e3deb826ad6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2d8ca5d28d58486daf85ed77074301e5/GRUModel_20250724_102840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0345dc4c447b4c21a47d11a73fbb13a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/ffbe042b627b4877aa32198a422e8dfa/GRUModel_20250724_065920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1866e4ecf37a4c84a252683d3bc9c2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/7d88e80a8aac4cea99184cee4072d3aa/GRUModel_20250723_203657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb12383c6e8942e88ef5d60bce810c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/c6eba5f871c04869aa6b249adb9d368d/GRUModel_20250723_223300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fff06c01e24af3904a6380d14f1a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2a70998b91a6404fa5e9522dee1e45fc/GRUModel_20250723_205917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5609ae31d03d4cbaa28bfbaef978e148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Loss: 1.13057 | ACCURACY: 0.65886 | AUROC: 0.72402 | F1: 0.21481 | MATTHEWS: 0.17957 | LR: 0.00281:  64%|██████▍   | 32/50 [16:22<09:12, 30.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 32, restoring model from epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/24 11:32:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run capricious-shrimp-71 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/e7bb809f1a2f41f29a49fc95e92b7f78\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/9a028m1a.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/4l2lyfwk.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=47818', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/9a028m1a.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/4l2lyfwk.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_model0z1rr3xk/prophet_model-20250724113232.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:32:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:32:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/m7wuz2gg.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/0gukrctd.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84954', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/m7wuz2gg.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/0gukrctd.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelgaj9z2gk/prophet_model-20250724113232.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:32:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:32:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/qnt0ck9s.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/dgf7idmn.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=5378', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/qnt0ck9s.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/dgf7idmn.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelarxcws4u/prophet_model-20250724113232.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:32:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:32:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f23b8ed7cd1b422fba1cb1a7289c1b12/GRUModel_20250724_061750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ddbaecee8442b49a74f12484939dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f1269821006f477d8424259e3ada789c/GRUModel_20250723_224211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d127a860f6c749b881fbeed013a6d279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2d8ca5d28d58486daf85ed77074301e5/GRUModel_20250724_102840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81238b39598449b49559fe9b42ef3b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/ffbe042b627b4877aa32198a422e8dfa/GRUModel_20250724_065920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a161d3919d5b4809bf2f6cd2fdcb06ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/7d88e80a8aac4cea99184cee4072d3aa/GRUModel_20250723_203657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8607d8e2260e4a8b8519f0406bc91b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/c6eba5f871c04869aa6b249adb9d368d/GRUModel_20250723_223300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4db1bec44624ceeb17fe5804739bfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2a70998b91a6404fa5e9522dee1e45fc/GRUModel_20250723_205917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde0fb0250744381936ed1f5445cc9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Loss: 1.14772 | ACCURACY: 0.67534 | AUROC: 0.71556 | F1: 0.20976 | MATTHEWS: 0.16580 | LR: 0.00281:  60%|██████    | 30/50 [15:14<10:09, 30.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30, restoring model from epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/24 11:48:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run peaceful-owl-246 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/94ca71f322fe4290b0e0d16bdbcdb059\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n",
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/te0yvthg.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/np3t3z_6.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=61552', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/te0yvthg.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/np3t3z_6.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modelwunn5kfv/prophet_model-20250724114814.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:48:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:48:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/wdr3abf6.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/qrzv4vb3.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=28583', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/wdr3abf6.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/qrzv4vb3.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modeluwx2a3_y/prophet_model-20250724114815.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:48:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:48:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/eby16gyh.json\n",
      "DEBUG:cmdstanpy:input tempfile: /var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d1my8sfi.json\n",
      "DEBUG:cmdstanpy:idx 0\n",
      "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
      "DEBUG:cmdstanpy:CmdStan args: ['/Users/guillaumedecina-halmi/miniforge3/lib/python3.12/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63425', 'data', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/eby16gyh.json', 'init=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/d1my8sfi.json', 'output', 'file=/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/tmpn22451t0/prophet_modeluvtw__ol/prophet_model-20250724114815.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
      "11:48:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "INFO:cmdstanpy:Chain [1] start processing\n",
      "11:48:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "INFO:cmdstanpy:Chain [1] done processing\n",
      "INFO:src.data.feature_engineer:Transforming new data with fitted features...\n",
      "INFO:src.data.feature_engineer:Engineering features...\n",
      "INFO:src.data.tensor_factory:Converting financial series to tensors...\n",
      "INFO:src.data.tensor_factory:Scaling financial data with RobustScaler...\n",
      "INFO:src.data.tensor_factory:Shaped financial data tensor: (6296, 3, 4)\n",
      "INFO:src.data.tensor_factory:Shaped macro data tensor: torch.Size([3, 36])\n",
      "INFO:__main__:Device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f23b8ed7cd1b422fba1cb1a7289c1b12/GRUModel_20250724_061750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4372032b9242699fa5f32efbdbc6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/f1269821006f477d8424259e3ada789c/GRUModel_20250723_224211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80ec6e9d38f4bf3b1104bf2ce9c393d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2d8ca5d28d58486daf85ed77074301e5/GRUModel_20250724_102840\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86abe8d6d14454dac8efce647433bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/ffbe042b627b4877aa32198a422e8dfa/GRUModel_20250724_065920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3463cf36c47d4a27b5bb4df274ec0852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/7d88e80a8aac4cea99184cee4072d3aa/GRUModel_20250723_203657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81661911177b49e39c32d64ec601128a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/c6eba5f871c04869aa6b249adb9d368d/GRUModel_20250723_223300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a795ca8f8324ad7b52be25a94e2276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: runs:/2a70998b91a6404fa5e9522dee1e45fc/GRUModel_20250723_205917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adbeedf13ee472a900a01e92ef93480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Loss: 1.13148 | ACCURACY: 0.65766 | AUROC: 0.72367 | F1: 0.21565 | MATTHEWS: 0.18153 | LR: 0.00375:  58%|█████▊    | 29/50 [14:58<10:50, 30.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 29, restoring model from epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[31m2025/07/24 12:03:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "INFO:src.data.loaders:Reading file: ../data/demo_data.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run amazing-seal-389 at: http://127.0.0.1:8080/#/experiments/387584985157093548/runs/3ee011a5c66542a9b893a2dfbe9f7331\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/387584985157093548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.loaders:Dropping high-revenue outliers...\n",
      "INFO:src.data.loaders:Loading 3 macroeconomic series...\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
      "/Users/guillaumedecina-halmi/Documents/202504 Bankruptcy prediction on restaurants/src/data/loaders.py:136: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"]=pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataframe has less than 2 non-NaN rows.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m     config=yaml.safe_load(stream)\n\u001b[32m      6\u001b[39m     config = TrainConfig(**config)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mtrain_model_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[32m     10\u001b[39m gc.collect()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_model_from_config\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model_from_config\u001b[39m(cfg: TrainConfig) -> EnsembleGRU:\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Main training function\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfirm_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_paths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmacro_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbankruptcy_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompany_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevenue_cap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_fract\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscheduler_patience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(company_path, macro_paths, bankruptcy_col, company_col, revenue_cap, n_models, metrics, seed, device, num_layers, hidden_sizes, epochs, lr, train_fract, threshold, dropout, scheduler_factor, scheduler_patience, min_lr)\u001b[39m\n\u001b[32m     83\u001b[39m logging.basicConfig(level = logging.INFO)\n\u001b[32m     85\u001b[39m ingestion = IngestionPipeline(\n\u001b[32m     86\u001b[39m     company_path=company_path,\n\u001b[32m     87\u001b[39m     macro_paths=macro_paths,\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     revenue_cap=revenue_cap\n\u001b[32m     91\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mingestion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m X, M, y = ingestion.get_tensors()\n\u001b[32m     96\u001b[39m dataset = DualInputSequenceDataset(\n\u001b[32m     97\u001b[39m     firm_tensor = X,\n\u001b[32m     98\u001b[39m     macro_tensor = M,\n\u001b[32m     99\u001b[39m     labels = y\n\u001b[32m    100\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/data/pipeline.py:53\u001b[39m, in \u001b[36mIngestionPipeline.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     49\u001b[39m years=\u001b[38;5;28mself\u001b[39m.company_loader.years\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m.tensor_factory=TensorFactory(years=years)\n\u001b[32m     52\u001b[39m macro_series=[\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[43mMacroTimeSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmacro_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(macro_df.shape[\u001b[32m1\u001b[39m])\n\u001b[32m     54\u001b[39m ]\n\u001b[32m     56\u001b[39m label_col=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbankrupt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myears[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mself\u001b[39m.feature_engineer=FeatureEngineer(years=years, label_col=label_col)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/data/time_series.py:156\u001b[39m, in \u001b[36mMacroTimeSeries.__init__\u001b[39m\u001b[34m(self, data, years, n_periods, order, method)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m years:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mself\u001b[39m._cut()\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28mself\u001b[39m.predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/data/time_series.py:174\u001b[39m, in \u001b[36mMacroTimeSeries._forecast\u001b[39m\u001b[34m(self, method, n_periods, order)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forecast\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, n_periods: \u001b[38;5;28mint\u001b[39m, order: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mprophet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m         \u001b[38;5;28mself\u001b[39m.forecast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforecast_prophet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_periods\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33marima\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    176\u001b[39m         \u001b[38;5;28mself\u001b[39m.forecast = \u001b[38;5;28mself\u001b[39m.forecast_ARIMA(n_periods, order)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/202504 Bankruptcy prediction on restaurants/src/data/time_series.py:220\u001b[39m, in \u001b[36mMacroTimeSeries.forecast_prophet\u001b[39m\u001b[34m(self, n_periods)\u001b[39m\n\u001b[32m    217\u001b[39m data = pd.DataFrame([data.index, data.values], index = [\u001b[33m\"\u001b[39m\u001b[33mds\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m]).T\n\u001b[32m    219\u001b[39m model = Prophet()\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m model_fit = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m freq = pd.infer_freq(data[\u001b[33m\"\u001b[39m\u001b[33mds\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/prophet/forecaster.py:1217\u001b[39m, in \u001b[36mProphet.fit\u001b[39m\u001b[34m(self, df, **kwargs)\u001b[39m\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.history \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mProphet object can only be fit once. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1215\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mInstantiate a new object.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1217\u001b[39m model_inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1218\u001b[39m initial_params = \u001b[38;5;28mself\u001b[39m.calculate_initial_params(model_inputs.K)\n\u001b[32m   1220\u001b[39m dat = dataclasses.asdict(model_inputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/prophet/forecaster.py:1132\u001b[39m, in \u001b[36mProphet.preprocess\u001b[39m\u001b[34m(self, df, **kwargs)\u001b[39m\n\u001b[32m   1130\u001b[39m history = df[df[\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m].notnull()].copy()\n\u001b[32m   1131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m history.shape[\u001b[32m0\u001b[39m] < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mDataframe has less than 2 non-NaN rows.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1133\u001b[39m \u001b[38;5;28mself\u001b[39m.history_dates = pd.to_datetime(pd.Series(history[\u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m].unique(), name=\u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m)).sort_values()\n\u001b[32m   1135\u001b[39m \u001b[38;5;28mself\u001b[39m.history = \u001b[38;5;28mself\u001b[39m.setup_dataframe(history, initialize_scales=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Dataframe has less than 2 non-NaN rows."
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "while True:\n",
    "    with open(\"../config/ensemble_config.yml\") as stream:\n",
    "        config=yaml.safe_load(stream)\n",
    "        config = TrainConfig(**config)\n",
    "    model = train_model_from_config(config)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "from src.models.gru import GRUModel\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "model_uri = 'runs:/ded35c0837614ae2ab5feafda113ee9c/GRUModel_20250702_021258'\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b840dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d17982",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs = runs.sort_values(by = \"metrics.val_matthews\", ascending = False)[:7]\n",
    "selected_runs.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01661e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.artifacts\n",
    "\n",
    "\n",
    "mlflow.artifacts.download_artifacts(run_id=\"fe05629c8fa04c18a6e37553051db968\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs[\"artifact_uri\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = run_ids[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae462131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecc465",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64080353",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.pytorch.load_model(\"runs:/bb5b7d115ac04197a760a5d7aba049e9/GRUModel_20250701_233333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "model_paths = []\n",
    "artifacts = client.list_artifacts(run_ids[89])\n",
    "for artifact in artifacts:\n",
    "    if artifact.is_dir and artifact.path.starts_with(\"GRUModel_\"):\n",
    "        model_name = artifact.path\n",
    "        model_uri = f\"runs/.../{model_name}\"\n",
    "        model_paths.append((run.infomodel_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def get_best_models(n_models: int = 7, metric: str = \"val_matthews\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    client = MlflowClient()\n",
    "    \n",
    "    runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    selected_runs = runs.sort_values(by = \"metrics.\" + metric, ascending = False)[:n_models][\"run_id\"]\n",
    "    selected_runs.reset_index(inplace=True)\n",
    "    \n",
    "    model_paths = []\n",
    "    \n",
    "    for run in selected_runs:\n",
    "        run_id = run.info.run_id\n",
    "        artifacts = client.list_artifacts(run_id)\n",
    "        \n",
    "        for artifact in artifacts:\n",
    "            if artifact.is_dir and artifact.path.starts_with(\"GRUModel_\"):\n",
    "                model_name = artifact.path\n",
    "                model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "                model_paths.append(model_uri)\n",
    "\n",
    "    models = []\n",
    "\n",
    "    for model_uri in model_paths:\n",
    "        model = mlflow.pytorch.load_model(model_uri = model_uri)\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef740f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_best_models()\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "selected_runs = runs.sort_values(by = \"metrics.val_matthews\", ascending = False)[:7][\"tags.mlflow.log-model.history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027daea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(selected_runs[101], r\"\\\"$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_runs[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1be063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(n_models: int = 7, metric: str = \"val_matthews\"):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    runs = mlflow.search_runs(experiment_names=[\"bankruptcy-predictions\"])\n",
    "    selected_runs = runs.sort_values(by = \"metrics.\" + metric, ascending = False)[:n_models][\"run_id\"]\n",
    "    for run in selected_runs:\n",
    "        model_uri = \"runs:/\" + run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71398988",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f76a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
